{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing  modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose,STL\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to find % change for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing  modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose,STL\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing  modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose,STL\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to numeric (ignore errors for non-numeric values)\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percent change for all columns and create new columns\n",
    "for column in df.columns:\n",
    "    df[column + '_Percent_Change'] = ((df[column] - df[column].shift(1)) / df[column].shift(1)) * 100\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unwanted columns\n",
    "df = df .drop(columns= ['NATURAL GAS', 'GOLD', 'WTI CRUDE', 'BRENT CRUDE', 'SOYBEANS',\n",
    "       'CORN', 'COPPER', 'ALUMINIUM', 'ZINC', 'NICKEL', 'WHEAT', 'SUGAR',\n",
    "       'COFFEE', 'COTTON', 'BOND_10Y',\n",
    "       'Dollar_Index','Date','Date_Percent_Change'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cheaking for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1  =pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. by using visual representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box plot\n",
    "\n",
    "# Assuming 'your_data' is a DataFrame with your dataset\n",
    "sns.set(style=\"whitegrid\")  # Set the plot style\n",
    "\n",
    "# Create box plots for each feature\n",
    "plt.figure(figsize=(12, 6))  # Adjust the figure size as needed\n",
    "sns.boxplot(data=df, orient=\"h\")  # Horizontal box plots\n",
    "plt.title(\"Box Plots for Features\")\n",
    "plt.xlabel(\"Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation Forestt\n",
    "isolation_forest = IsolationForest()\n",
    "isolation_forest_labels = isolation_forest.fit_predict(df)\n",
    "isolation_forest_outliers = np.where(isolation_forest_labels == -1)[0]\n",
    "len(isolation_forest_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z Score\n",
    "from scipy import stats\n",
    "z_scores = stats.zscore(df)\n",
    "threshold = 3  # You can adjust this threshold as needed\n",
    "z_score_outliers = np.where(np.abs(z_scores) > threshold)[0]\n",
    "len(z_score_outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IQR\n",
    "Q1 = np.percentile(df, 25)\n",
    "Q3 = np.percentile(df, 75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "iqr_outliers = np.where((df < lower_bound) | (df > upper_bound))[0]\n",
    "len(iqr_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = set(z_score_outliers) & set(isolation_forest_outliers) & set(iqr_outliers)\n",
    "len(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(outliers)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to numeric, handling errors\n",
    "df1 = df1.apply(pd.to_numeric, errors='coerce')\n",
    "df1 = df1[(df1 > -20) & (df1 < 20)]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.dropna()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box plot\n",
    "\n",
    "# Assuming 'your_data' is a DataFrame with your dataset\n",
    "sns.set(style=\"whitegrid\")  # Set the plot style\n",
    "\n",
    "# Create box plots for each feature\n",
    "plt.figure(figsize=(12, 6))  # Adjust the figure size as needed\n",
    "sns.boxplot(data=df1, orient=\"h\")  # Horizontal box plots\n",
    "plt.title(\"Box Plots for Features\")\n",
    "plt.xlabel(\"Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose a commodity's time series data\n",
    "decomposition = seasonal_decompose(df1['NATURAL GAS_Percent_Change'], model='additive', period=365)\n",
    "#  Filter residuals greater than 25 and less than -25\n",
    "residuals = decomposition.resid\n",
    "residuals = np.where((residuals > 25) | (residuals < -25), np.nan, residuals)\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose a commodity's time series data\n",
    "decomposition = seasonal_decompose(df1['GOLD_Percent_Change'], model='additive', period=365)\n",
    "#  Filter residuals greater than 25 and less than -25\n",
    "residuals = decomposition.resid\n",
    "residuals = np.where((residuals > 25) | (residuals < -25), np.nan, residuals)\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose a commodity's time series data\n",
    "decomposition = seasonal_decompose(df1['WTI CRUDE_Percent_Change'], model='additive', period=365)\n",
    "#  Filter residuals greater than 25 and less than -25\n",
    "residuals = decomposition.resid\n",
    "residuals = np.where((residuals > 25) | (residuals < -25), np.nan, residuals)\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose a commodity's time series data\n",
    "decomposition = seasonal_decompose(df1['BRENT CRUDE_Percent_Change'], model='additive', period=365)\n",
    "#  Filter residuals greater than 25 and less than -25\n",
    "residuals = decomposition.resid\n",
    "residuals = np.where((residuals > 25) | (residuals < -25), np.nan, residuals)\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose a commodity's time series data\n",
    "decomposition = seasonal_decompose(df1['SOYBEANS_Percent_Change'], model='additive', period=365)\n",
    "#  Filter residuals greater than 25 and less than -25\n",
    "residuals = decomposition.resid\n",
    "residuals = np.where((residuals > 25) | (residuals < -25), np.nan, residuals)\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose a commodity's time series data\n",
    "decomposition = seasonal_decompose(df1['CORN_Percent_Change'], model='additive', period=365)\n",
    "#  Filter residuals greater than 25 and less than -25\n",
    "residuals = decomposition.resid\n",
    "residuals = np.where((residuals > 25) | (residuals < -25), np.nan, residuals)\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose a commodity's time series data\n",
    "decomposition = seasonal_decompose(df1['COPPER_Percent_Change'], model='additive', period=365)\n",
    "#  Filter residuals greater than 25 and less than -25\n",
    "residuals = decomposition.resid\n",
    "residuals = np.where((residuals > 25) | (residuals < -25), np.nan, residuals)\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose a commodity's time series data\n",
    "decomposition = seasonal_decompose(df1['ALUMINIUM_Percent_Change'], model='additive', period=365)\n",
    "#  Filter residuals greater than 25 and less than -25\n",
    "residuals = decomposition.resid\n",
    "residuals = np.where((residuals > 25) | (residuals < -25), np.nan, residuals)\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose a commodity's time series data\n",
    "decomposition = seasonal_decompose(df1['ZINC_Percent_Change'], model='additive', period=365)\n",
    "#  Filter residuals greater than 25 and less than -25\n",
    "residuals = decomposition.resid\n",
    "residuals = np.where((residuals > 25) | (residuals < -25), np.nan, residuals)\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose a commodity's time series data\n",
    "decomposition = seasonal_decompose(df1['SUGAR_Percent_Change'], model='additive', period=365)\n",
    "#  Filter residuals greater than 25 and less than -25\n",
    "residuals = decomposition.resid\n",
    "residuals = np.where((residuals > 25) | (residuals < -25), np.nan, residuals)\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose a commodity's time series data\n",
    "decomposition = seasonal_decompose(df1['COFFEE_Percent_Change'], model='additive', period=365)\n",
    "#  Filter residuals greater than 25 and less than -25\n",
    "residuals = decomposition.resid\n",
    "residuals = np.where((residuals > 25) | (residuals < -25), np.nan, residuals)\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose a commodity's time series data\n",
    "decomposition = seasonal_decompose(df1['COTTON_Percent_Change'], model='additive', period=365)\n",
    "#  Filter residuals greater than 25 and less than -25\n",
    "residuals = decomposition.resid\n",
    "residuals = np.where((residuals > 25) | (residuals < -25), np.nan, residuals)\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose a commodity's time series data\n",
    "decomposition = seasonal_decompose(df1['BOND_10Y_Percent_Change'], model='additive', period=365)\n",
    "#  Filter residuals greater than 25 and less than -25\n",
    "residuals = decomposition.resid\n",
    "residuals = np.where((residuals > 25) | (residuals < -25), np.nan, residuals)\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose a commodity's time series data\n",
    "decomposition = seasonal_decompose(df1['Dollar_Index_Percent_Change'], model='additive', period=365)\n",
    "#  Filter residuals greater than 25 and less than -25\n",
    "residuals = decomposition.resid\n",
    "residuals = np.where((residuals > 25) | (residuals < -25), np.nan, residuals)\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for data where outliers is there \n",
    "corr_matrix2 = df1.corr()\n",
    "plt.figure(figsize=(30, 24))\n",
    "sns.heatmap(corr_matrix2, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data without feature enginnering\n",
    "df1.to_csv('df1.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature enginnering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new dataset \n",
    "df2 = df1.copy()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the number of lags and the window size for moving averages\n",
    "num_lags = [1,3,5,7,9,20,21,100,200]\n",
    "window_size = [5,10,20,21,100,200]\n",
    "# Iterate through the columns of the dataset\n",
    "for col in df1.columns:\n",
    "    for num in num_lags:\n",
    "        for lag in range(1, num+ 1):\n",
    "            df2[f'{col}_Lag{lag}'] = df1[col].shift(lag)\n",
    "\n",
    "    for win in window_size:\n",
    "        # Moving Averages SMA\n",
    "        df2[f'{col}_SMA{win}'] = df1[col].rolling(window=win).mean()\n",
    "        # Moving Averages EMA\n",
    "        df2[f'{col}_EMA{win}'] = df1[col].ewm(span=win, adjust=False).mean()\n",
    "\n",
    "        # Standard Deviation\n",
    "        df2[f'{col}_STD{win}'] = df1[col].rolling(window=win).std()\n",
    "\n",
    "        # Historical Volatility (assuming daily returns)\n",
    "        returns = df1[col]\n",
    "        df2[f'{col}_HV'] = returns.rolling(window=win).std() * (252 ** 0.5)  # Annualized volatility (252 trading days)\n",
    "\n",
    "\n",
    "   # RSI Calculation\n",
    "    delta = df1[col]\n",
    "    gain = (delta.where(delta > 0, 0))\n",
    "    loss = (-delta.where(delta < 0, 0))\n",
    "    rs = gain / loss\n",
    "    df2[f'{col}_RSI'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "    # MACD Calculation\n",
    "    df2[f'{col}_EMA12'] = df1[col].ewm(span=12, adjust=False).mean()\n",
    "    df2[f'{col}_EMA26'] = df1[col].ewm(span=26, adjust=False).mean()\n",
    "    df2[f'{col}_MACD'] = df2[f'{col}_EMA12'] - df2[f'{col}_EMA26']\n",
    "               \n",
    "    # Stochastic Oscillator\n",
    "    min = df1[col].min()\n",
    "    max = df1[col].max()\n",
    "    df2[f'{col}_Stochastic_Oscillator'] = ((df1[col] - min) / \n",
    "                                               (max - min)) * 100\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Get all combinations of column pairs\n",
    "column_pairs = list(itertools.combinations(df1.columns, 2))\n",
    "\n",
    "for col1, col2 in column_pairs:\n",
    "    # Inter-Commodity Spread Calculation:\n",
    "    df2[f'{col1}_{col2}_Spread'] = df1[col1] - df1[col2]\n",
    "\n",
    "    # Ratio Calculation between Commodities:\n",
    "    df2[f'{col1}_{col2}_Ratio'] = df1[col1] / df1[col2]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.replace([np.inf, -np.inf], np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.dropna()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('final_df.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
